{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing - Build a data processing pipeline to process electronic medical reports (EMR) using Amazon Textract and Comprehend Medical\n",
    "\n",
    "In this notebook, we will walkthrough on how to build a data processing pipeline that will process electronic medical reports (EMR) in PDF format to extract relevant medical information by using the following AWS services:\n",
    "\n",
    "- [Textract](https://aws.amazon.com/textract/): To extract text from the PDF medical report\n",
    "- [Comprehend Medical](https://aws.amazon.com/comprehend/medical/): To extract relevant medical information from the output of textract\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Setupe Environment](#Setup-Environment)\n",
    "1. [Extract text using Amazon Textract](#Step-1:-Process-PDF-with-Amazon-Textract)\n",
    "1. [Extract medical information using Amazon Comprehend Medical](#Step-2:-Extract-medical-information-with-Amazon-Comprehend-Medical)\n",
    "1. [Clean up resources](#Clean-up-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Objective\n",
    "\n",
    "The objective of this section of the workshop is to learn how to use Amazon Textract and Comprehend Medical to extract the medical information from an electronic medical report in PDF format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Setup environment\n",
    "\n",
    "Before be begin, let us setup our environment. We will need the following:\n",
    "\n",
    "* Amazon Textract Results Parser `textract-trp` to process our Textract results.\n",
    "* Python libraries \n",
    "* Pre-processing functions that will help with processing and visualization of our results. For the purpose of this workshop, we have provided a pre-processing function library that can be found in [util/preprocess.py](./util/preprocess.py)\n",
    "\n",
    "Note: `textract-trp` will require Python 3.6 or newer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textract-trp in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import sagemaker\n",
    "import os \n",
    "import trp\n",
    "from util.preprocess import *\n",
    "import pandas as pd\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/medical_notes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 1: Process PDF with Amazon Textract\n",
    "\n",
    "In this section we will be extracting the text from a medical report in PDF format using Textract. To facilitate this workshop, we have generated a [sample PDF medical report](./data/sample_report_1.pdf) using the [MTSample dataset](https://www.kaggle.com/tboyle10/medicaltranscriptions) from kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Textract\n",
    "Amazon Textract can detect lines of text and the words that make up a line of text. Textract can handle documents in either synchronous or asynchronous processing:\n",
    "+ [synchronous API](https://docs.aws.amazon.com/textract/latest/dg/sync.html): supports *The input document must be an image in `JPEG` or `PNG` format*. Single page document analysis can be performed using a Textract synchronous operation.\n",
    "    1. *`detect_document_text`*: detects text in the input document. \n",
    "    2. *`analyze_document`*: analyzes an input document for relationships between detected items.\n",
    "+ [asynchronous API](https://docs.aws.amazon.com/textract/latest/dg/async.html): *can analyze text in documents that are in `JPEG`, `PNG`, and `PDF` format. Multi page processing is an asynchronous operation. The documents are stored in an Amazon S3 bucket. Use DocumentLocation to specify the bucket name and file name of the document.*\n",
    "    1. for context analysis:\n",
    "        1. *`start_document_text_detection`*: starts the asynchronous detection of text in a document. \n",
    "        2. *`get_document_text_detection`*: gets the results for an Amazon Textract asynchronous operation that detects text in a document.\n",
    "    2. for relationships between detected items :\n",
    "        1. *`start_document_analysis`*: starts the asynchronous analysis of relationship in a document. \n",
    "        2. *`get_document_analysis`*: Gets the results for an Amazon Textract asynchronous operation that analyzes text in a document\n",
    "  \n",
    "For detailed api, refer to documentation [here](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html#Textract.Client.analyze_document).\n",
    "\n",
    "In this demo, as the input is in pdf format and has multiple pages, we will be using the multi page textract operation, we will need to need upload our sample medical record to an S3 bucket. Run the next cell to upload our sample medical report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName =  'sample_report_1.pdf'\n",
    "fileUploadPath = os.path.join('./data', fileName)\n",
    "textractObjectName = os.path.join(prefix, 'data', fileName)\n",
    "\n",
    "# Upload medical report file\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(textractObjectName).upload_file(fileUploadPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start text detection asynchonously in the pdf\n",
    "In the next step, we will start the asynchronous textract operation by calling the `start_document_analysis()` function. The function will kickoff an asynchronous job that will process our medical report file in the stipulated S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job id is:  20e30ffda31b82200800f798f5b7c1f037e3db16acc770d20bac3b4bbdb98777\n"
     ]
    }
   ],
   "source": [
    "textract = boto3.client('textract')\n",
    "response = textract.start_document_analysis(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket,\n",
    "            'Name': textractObjectName\n",
    "        }},\n",
    "    FeatureTypes=[\n",
    "        'TABLES',\n",
    "    ]\n",
    "    )\n",
    "\n",
    "textractJobId = response[\"JobId\"]\n",
    "print('job id is: ',textractJobId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait until the job finishes\n",
    "\n",
    "As the job is kicked off in the background, we can monitor the progress of the job by calling the `get_document_analysis()` function and passing the job id of the job that we created. \n",
    "\n",
    "Run the next cell and wait for the Textract Job status to return a SUCCEEDED status.\n",
    "the outcome is in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textract Job status: IN_PROGRESS\n",
      "Textract Job status: SUCCEEDED\n",
      "CPU times: user 64.2 ms, sys: 0 ns, total: 64.2 ms\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time.sleep(5)\n",
    "response = textract.get_document_analysis(JobId=textractJobId)\n",
    "status = response[\"JobStatus\"]\n",
    "\n",
    "while(status == \"IN_PROGRESS\"):\n",
    "    time.sleep(5)\n",
    "    response = textract.get_document_analysis(JobId=textractJobId)\n",
    "    status = response[\"JobStatus\"]\n",
    "    print(\"Textract Job status: {}\".format(status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract textract results\n",
    "Now that we've successfully extracted the text from the medical report, let us extract the textract results and consolidate the text so that we can pass it to Comprehend Medical to start extract medical information from the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 133 ms, sys: 7.55 ms, total: 140 ms\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pages = []\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "response = textract.get_document_analysis(JobId=textractJobId)\n",
    "\n",
    "pages.append(response)\n",
    "\n",
    "nextToken = None\n",
    "if('NextToken' in response):\n",
    "    nextToken = response['NextToken']\n",
    "\n",
    "while(nextToken):\n",
    "    time.sleep(5)\n",
    "\n",
    "    response = textract.get_document_analysis(JobId=textractJobId, NextToken=nextToken)\n",
    "\n",
    "    pages.append(response)\n",
    "    print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output from Textract\n",
    "\n",
    "Let's take a look at the output from textract by using the trp library to extract and format the textract results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of document is 2\n",
      "\u001b[1mResults from page 1: \n",
      "\u001b[0m Discharge Summary\n",
      "Name\n",
      "Terri Hodosy\n",
      "Birth Date\n",
      "10/22/1962\n",
      "Gender\n",
      "female\n",
      "Post Code\n",
      "1826\n",
      "Admission Date\n",
      "01/01/2020\n",
      "Discharge Date\n",
      "01/20/2020\n",
      "Medications\n",
      "HISTORY: This 15-day-old female presents to Children's Hospital and transferred from Hospital\n",
      "Emergency Department for further evaluation. Information is obtained in discussion with the mother\n",
      "and the grandmother in review of previous medical records. This patient had the onset on the day of\n",
      "presentation of a jelly-like red-brown stool started on Tuesday morning. Then, the patient was noted\n",
      "to vomit after feeds. The patient was evaluated at Hospital with further evaluation with laboratory\n",
      "data showing a white blood cell count elevated at 22.2; hemoglobin 14.1; sodium 138; potassium 7.2,\n",
      "possibly hemolyzed; chloride 107; CO2 23; BUN 17; creatinine 1.2; and glucose of 50, which was\n",
      "repeated and found to be stable in that range. The patient underwent a barium enema, which was\n",
      "read by the radiologist as negative. The patient was transferred to Children's Hospital for further\n",
      "evaluation after being given doses of ampicillin, cefotaxime, and Rocephin.,P PAST MEDICAL\n",
      "HISTORY: Further, the patient was born in Hospital. Birth weight was 6 pounds 4 ounces. There\n",
      "was maternal hypertension. Mother denies group B strep or herpes. Otherwise, no past medical\n",
      "history.,IMMUNIZATIONS: None Oday.,MEDICATIONS: Thrush medicine identified as\n",
      "nystatin.,ALLERGIES: Denied.,P PAST SURGICAL HISTORY: Denied. SOCIAL HISTORY: Here\n",
      "with mother and grandmother, lives at home. There is no smoking at home. FAMILY HISTORY:\n",
      "None noted exposures. REVIEW OF SYSTEMS: The patient is fed Enfamil, bottle-fed. Has had\n",
      "decreased feeding, has had vomiting, has had diarrhea, otherwise negative on the 10 plus systems\n",
      "reviewed., ,PHYSICAL EXAMINATION:, VITAL SIGNS/GENERAL: On physical examination, the initial\n",
      "temperature 97.5, pulse 140, respirations 48 on this 2 kg 15-day-old female who is small,\n",
      "well-developed female, age appropriate., HEENT: Head is atraumatic and normocephalic with a soft\n",
      "and flat anterior fontanelle. Pupils are equal, round, and reactive to light. Grossly conjugate.\n",
      "Bilateral red reflex appreciated bilaterally. Clear TMs, nose, and oropharynx. There is a kind\n",
      "of\n",
      "abundant thrush and white patches on the tongue., NECK: Supple, full, painless and nontender\n",
      "range of motion.,CHEST motion., ,CHEST: Clear to auscultation, equal, and stable., HEART: Regular without rubs or\n",
      "murmurs, and femoral pulses are appreciated bilaterally.,ABDOMEN: Soft and nontender. No\n",
      "hepatosplenomegaly or Ses.,GENITALIA Female genitalia is present on a visual\n",
      "examination.,SK No significant bruising, lesions, or rash. h.,EXTREMITIES: Moves all extremities,\n",
      "and nontender. No deformity.,NEUROLOGICALLY Eyes open, moves all extremities, grossly age\n",
      "appropriate.,N MEDICAL DECISION MAKING: The differential entertained on this patient includes\n",
      "\n",
      "\u001b[1mResults from page 2: \n",
      "\u001b[0m upper respiratory infection, gastroenteritis, urinary tract infection, dehydration, acidosis, and viral\n",
      "syndrome. The patient is evaluated in the emergency department laboratory data, which shows a\n",
      "white blood cell count of 13.1, hemoglobin 14.0, platelets 267,000, 7 stabs, 68 segs, 15 lymphs, and\n",
      "9 monos. Serum electrolytes not normal. Sodium 138, potassium 5.0, chloride 107, CO2 acidotic at\n",
      "18, glucose normal at 88, and BUN markedly elevated at 22 as is the creatinine of 1.4. AST and ALT\n",
      "were elevated as wel at 412 and 180 respectively. A cath urinalysis showing no signs of infection.\n",
      "Spina fluid evaluation, please see procedure note below. White count O, red count 2060. Gram\n",
      "stain negative. .,PROCEDURE NOTE: After discussion of the risks, benefits, and indications, and\n",
      "obtaining informed consent with the family and their agreement to proceed, this patient was placed in\n",
      "the left lateral position and using aseptic Betadine preparation, sterile draping, and sterile technique\n",
      "pursued throughout, this patient's L4- L5 interspace was anesthetized with the 1% lidocaine solution\n",
      "following the above sterile preparation, entered with a 22-gauge styletted spinal needle of\n",
      "approximately 0.5 mL clear CSF, they were very slow to obtain. The fluid was obtained, the needle\n",
      "was removed, and sterile bandage was placed. The fluid was sent to laboratory for further evaluation\n",
      "(aunt and grandmother) were present throughout the period of time during this procedure and the\n",
      "procedure was tolerated well. An i-STAT initially obtained showed somewhat of an acidosis with a\n",
      "base excess of -12. A repeat i-STAT after a bolus of normal saline and a second bolus of normal\n",
      "saline, her maintenance rate of D5 half showed a base excess of -11, which is slowly improving, but\n",
      "not very fast. Based on the above having this patient consulted to the Hospitalist Service at 2326\n",
      "hours of request, this patient was consulted to PICU with the plan that the patient need to have\n",
      "continued IV fluids. Showing signs of dehydration, a third bolus of normal saline was provided, twice\n",
      "maintenance D5 half was continued. The patient was admitted to the Hospitalist Service for\n",
      "continued IV fluids. The patient maintains to have clear lungs, has been feeding well here in the\n",
      "department, took virtually a whole small bottle of the appropriate formula. She has not had any\n",
      "vomiting, is burping. The patient is admitted for continued close observation and rehydration due to\n",
      "the working diagnoses of gastroenteritis, metabolic acidosis, and dehydration. Critical care time on\n",
      "this patient is less than 30 minutes, exclusive, otherwise time has been spent evaluating this patient\n",
      "according to this patient's care and admission to the Hospitalist Service.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = trp.Document(pages)\n",
    "print(\"Total length of document is\",len(doc.pages))\n",
    "idx=1\n",
    "for page in doc.pages:\n",
    "    print(color.BOLD + f\"Results from page {idx}: \\n\" + color.END, page.text)\n",
    "    idx=idx+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 2: Extract medical information with Amazon Comprehend Medical\n",
    "\n",
    "## About Amazon Comprehend Medical\n",
    "\n",
    "Comprehend Medical detects useful information in unstructured clinical text. As much as 75% of all health record data is found in unstructured text such as physician's notes, discharge summaries, test results, and case notes. Amazon Comprehend Medical uses Natural Language Processing (NLP) models to sort through text for valuable information. Amazon Comprehend Medical only detects medical entities in English language texts.\n",
    "\n",
    "With Amazon Comprehend Medical, you can perform the following on your documents:\n",
    "\n",
    "- [Detect Entities (Version 2)](https://docs.aws.amazon.com/comprehend/latest/dg/extracted-med-info-V2.html) - Examine unstructured clinical text to detect textual references to medical information such as medical condition, treatment, tests and results, and medications. This version uses a new model and changes the way some entities are returned in the output. For more information, see [DetectEntitiesV2](https://docs.aws.amazon.com/comprehend/latest/dg/API_medical_DetectEntitiesV2.html).\n",
    "\n",
    "- [Detect PHI (Verdion 2)](https://docs.aws.amazon.com/comprehend/latest/dg/how-medical-phi.html) â€”Examine unstructured clinical text to detect textual references to protected health information (PHI) such as names and addresses.\n",
    "\n",
    "\n",
    "In this workshop, we will be using the detect entities function to extract the medical condition. In the following cell, we will be processing the text on each page in batches of 20,000 UTF-8 characters. This is because Comprehend Medical has a maximum document size of 20,000 bytes (reference: https://docs.aws.amazon.com/comprehend/latest/dg/guidelines-and-limits-med.html). Once we've processed the text, we will then stich up the response into a into a single variable where we can either save to a csv or use for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLength=10000\n",
    "\n",
    "comprehendResponse = []\n",
    "comprehend_medical_client = boto3.client(service_name='comprehendmedical', region_name='us-east-1')\n",
    "\n",
    "for page in doc.pages:\n",
    "    pageText = page.text\n",
    "    \n",
    "    for i in range(0, len(pageText), maxLength):\n",
    "        response = comprehend_medical_client.detect_entities_v2(Text=pageText[0+i:maxLength+i])\n",
    "        comprehendResponse.append(response)\n",
    "    patient_string = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review comprehend results\n",
    "The output of detect entities v2 can detect the following entities:\n",
    "\n",
    "- ANATOMY: Detects references to the parts of the body or body systems and the locations of those parts or systems.\n",
    "- MEDICAL_CONDITION: Detects the signs, symptoms, and diagnosis of medical conditions.\n",
    "- MEDICATION: Detects medication and dosage information for the patient.\n",
    "- PROTECTED_HEALTH_INFORMATION: Detects the patient's personal information.\n",
    "- TEST_TREATMENT_PROCEDURE: Detects the procedures that are used to determine a medical condition.\n",
    "- TIME_EXPRESSION: Detects entities related to time when they are associated with a detected entity.\n",
    "\n",
    "For this workshop, we will be using the MEDICAL_CONDITION entity to train our machine learning model. Let us take a look at some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDICAL_CONDITION</th>\n",
       "      <th>Score</th>\n",
       "      <th>Trait</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jelly-like red-brown stool</td>\n",
       "      <td>0.370149</td>\n",
       "      <td>SYMPTOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vomit</td>\n",
       "      <td>0.688994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B strep</td>\n",
       "      <td>0.455369</td>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>herpes</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thrush</td>\n",
       "      <td>0.835416</td>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decreased feeding</td>\n",
       "      <td>0.909020</td>\n",
       "      <td>SYMPTOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vomiting</td>\n",
       "      <td>0.996553</td>\n",
       "      <td>SYMPTOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diarrhea</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>SYMPTOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>well-developed</td>\n",
       "      <td>0.714349</td>\n",
       "      <td>SIGN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MEDICAL_CONDITION     Score      Trait  ID\n",
       "0  jelly-like red-brown stool  0.370149    SYMPTOM   1\n",
       "1                       vomit  0.688994        NaN   1\n",
       "2                hypertension  0.992857  DIAGNOSIS   1\n",
       "3                     B strep  0.455369  DIAGNOSIS   1\n",
       "4                      herpes  0.960876  DIAGNOSIS   1\n",
       "5                      Thrush  0.835416  DIAGNOSIS   1\n",
       "6           decreased feeding  0.909020    SYMPTOM   1\n",
       "7                    vomiting  0.996553    SYMPTOM   1\n",
       "8                    diarrhea  0.998125    SYMPTOM   1\n",
       "9              well-developed  0.714349       SIGN   1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use util function to extract all the medical conditions, confidence score, trait from json file \n",
    "df_cm=extractMC_v2(comprehendResponse[0])\n",
    "df_cm['ID']=1\n",
    "df_cm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clean up resources\n",
    "\n",
    "Finally, run the following cell to clean up the S3 resource we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'FT7R1J3R8TBY8P0G',\n",
       "  'HostId': 'pHFLcjTkU3huthy5o+mzEwg+rMJo8e3zQat278jaiQ6RrmqIEw1lhcDgNHcH39Zi8IXR+gDRzY8=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'pHFLcjTkU3huthy5o+mzEwg+rMJo8e3zQat278jaiQ6RrmqIEw1lhcDgNHcH39Zi8IXR+gDRzY8=',\n",
       "   'x-amz-request-id': 'FT7R1J3R8TBY8P0G',\n",
       "   'date': 'Sun, 20 Sep 2020 13:50:02 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(textractObjectName).delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
