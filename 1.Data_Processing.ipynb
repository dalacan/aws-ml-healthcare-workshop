{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing - Build a data processing pipeline to process electronic medical reports (EMR) using Amazon Textract and Comprehend Medical\n",
    "\n",
    "In this notebook, we will walkthrough on how to build a data processing pipeline that will process electronic medical reports (EMR) in PDF format to extract relevant medical information by using the following AWS services:\n",
    "\n",
    "- [Textract](https://aws.amazon.com/textract/): To extract text from the PDF medical report\n",
    "- [Comprehend Medical](https://aws.amazon.com/comprehend/medical/): To extract relevant medical information from the output of textract\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Setup Environment](#Setup-Environment)\n",
    "1. [Extract text using Amazon Textract](#Step-1:-Process-PDF-with-Amazon-Textract)\n",
    "1. [Extract medical information using Amazon Comprehend Medical](#Step-2:-Extract-medical-information-with-Amazon-Comprehend-Medical)\n",
    "1. [Clean up resources](#Clean-up-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Objective\n",
    "\n",
    "The objective of this section of the workshop is to learn how to use Amazon Textract and Comprehend Medical to extract the medical information from an electronic medical report in PDF format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Setup environment\n",
    "\n",
    "Before be begin, let us setup our environment. We will need the following:\n",
    "\n",
    "* Amazon Textract Results Parser `textract-trp` to process our Textract results.\n",
    "* Python libraries \n",
    "* Pre-processing functions that will help with processing and visualization of our results. For the purpose of this workshop, we have provided a pre-processing function library that can be found in [util/preprocess.py](./util/preprocess.py)\n",
    "\n",
    "Note: `textract-trp` will require Python 3.6 or newer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import sagemaker\n",
    "import os \n",
    "import trp\n",
    "from util.preprocess import *\n",
    "import pandas as pd\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/medical_notes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 1: Process PDF with Amazon Textract\n",
    "\n",
    "In this section we will be extracting the text from a medical report in PDF format using Textract. To facilitate this workshop, we have generated a [sample PDF medical report](./data/sample_report_1.pdf) using the [MTSample dataset](https://www.kaggle.com/tboyle10/medicaltranscriptions) from kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Textract\n",
    "Amazon Textract can detect lines of text and the words that make up a line of text. Textract can handle documents in either synchronous or asynchronous processing:\n",
    "+ [synchronous API](https://docs.aws.amazon.com/textract/latest/dg/sync.html): supports *The input document must be an image in `JPEG` or `PNG` format*. Single page document analysis can be performed using a Textract synchronous operation.\n",
    "    1. *`detect_document_text`*: detects text in the input document. \n",
    "    2. *`analyze_document`*: analyzes an input document for relationships between detected items.\n",
    "+ [asynchronous API](https://docs.aws.amazon.com/textract/latest/dg/async.html): *can analyze text in documents that are in `JPEG`, `PNG`, and `PDF` format. Multi page processing is an asynchronous operation. The documents are stored in an Amazon S3 bucket. Use DocumentLocation to specify the bucket name and file name of the document.*\n",
    "    1. for context analysis:\n",
    "        1. *`start_document_text_detection`*: starts the asynchronous detection of text in a document. \n",
    "        2. *`get_document_text_detection`*: gets the results for an Amazon Textract asynchronous operation that detects text in a document.\n",
    "    2. for relationships between detected items :\n",
    "        1. *`start_document_analysis`*: starts the asynchronous analysis of relationship in a document. \n",
    "        2. *`get_document_analysis`*: Gets the results for an Amazon Textract asynchronous operation that analyzes text in a document\n",
    "  \n",
    "For detailed api, refer to documentation [here](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html#Textract.Client.analyze_document).\n",
    "\n",
    "In this demo, as the input is in pdf format and has multiple pages, we will be using the multi page textract operation, we will need to need upload our sample medical record to an S3 bucket. Run the next cell to upload our sample medical report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName =  'sample_report_1.pdf'\n",
    "fileUploadPath = os.path.join('./data', fileName)\n",
    "textractObjectName = os.path.join(prefix, 'data', fileName)\n",
    "\n",
    "# Upload medical report file\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(textractObjectName).upload_file(fileUploadPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start text detection asynchonously in the pdf\n",
    "In the next step, we will start the asynchronous textract operation by calling the `start_document_analysis()` function. The function will kickoff an asynchronous job that will process our medical report file in the stipulated S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textract = boto3.client('textract')\n",
    "response = textract.start_document_analysis(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket,\n",
    "            'Name': textractObjectName\n",
    "        }},\n",
    "    FeatureTypes=[\n",
    "        'TABLES',\n",
    "    ]\n",
    "    )\n",
    "\n",
    "textractJobId = response[\"JobId\"]\n",
    "print('job id is: ',textractJobId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait until the job finishes\n",
    "\n",
    "As the job is kicked off in the background, we can monitor the progress of the job by calling the `get_document_analysis()` function and passing the job id of the job that we created. \n",
    "\n",
    "Run the next cell and wait for the Textract Job status to return a SUCCEEDED status.\n",
    "the outcome is in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time.sleep(5)\n",
    "response = textract.get_document_analysis(JobId=textractJobId)\n",
    "status = response[\"JobStatus\"]\n",
    "\n",
    "while(status == \"IN_PROGRESS\"):\n",
    "    time.sleep(5)\n",
    "    response = textract.get_document_analysis(JobId=textractJobId)\n",
    "    status = response[\"JobStatus\"]\n",
    "    print(\"Textract Job status: {}\".format(status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract textract results\n",
    "Now that we've successfully extracted the text from the medical report, let us extract the textract results and consolidate the text so that we can pass it to Comprehend Medical to start extract medical information from the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pages = []\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "response = textract.get_document_analysis(JobId=textractJobId)\n",
    "\n",
    "pages.append(response)\n",
    "\n",
    "nextToken = None\n",
    "if('NextToken' in response):\n",
    "    nextToken = response['NextToken']\n",
    "\n",
    "while(nextToken):\n",
    "    time.sleep(5)\n",
    "\n",
    "    response = textract.get_document_analysis(JobId=textractJobId, NextToken=nextToken)\n",
    "\n",
    "    pages.append(response)\n",
    "    print(\"Resultset page recieved: {}\".format(len(pages)))\n",
    "    nextToken = None\n",
    "    if('NextToken' in response):\n",
    "        nextToken = response['NextToken']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output from Textract\n",
    "\n",
    "Let's take a look at the output from textract by using the trp library to extract and format the textract results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = trp.Document(pages)\n",
    "print(\"Total length of document is\",len(doc.pages))\n",
    "idx=1\n",
    "for page in doc.pages:\n",
    "    print(color.BOLD + f\"Results from page {idx}: \\n\" + color.END, page.text)\n",
    "    idx=idx+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 2: Extract medical information with Amazon Comprehend Medical\n",
    "\n",
    "## About Amazon Comprehend Medical\n",
    "\n",
    "Comprehend Medical detects useful information in unstructured clinical text. As much as 75% of all health record data is found in unstructured text such as physician's notes, discharge summaries, test results, and case notes. Amazon Comprehend Medical uses Natural Language Processing (NLP) models to sort through text for valuable information. \n",
    "\n",
    "Using Amazon Comprehend Medical, you can quickly and accurately gather information, such as medical condition, medication, dosage, strength, and frequency from a variety of sources like doctors’ notes. Amazon Comprehend Medical uses advanced machine learning models to accurately and quickly identify medical information, such as medical conditions and medications, and determines their relationship to each other, for instance, medicine dosage and strength. Amazon Comprehend Medical can also link the detected information to medical ontologies such as ICD-10-CM or RxNorm\n",
    "\n",
    "Currently, Amazon Comprehend Medical only detects medical entities in English language texts.\n",
    "\n",
    "![Image of Comprehend Medical](https://d1.awsstatic.com/diagrams/product-page-diagram-Ontology-Linking_How-It-Works@2x.f2dde99f71240451d64b24bdd202573ff9a26d35.png)\n",
    "\n",
    "With Amazon Comprehend Medical, you can perform the following on your documents:\n",
    "\n",
    "- [Detect Entities (Version 2)](https://docs.aws.amazon.com/comprehend/latest/dg/extracted-med-info-V2.html) - Examine unstructured clinical text to detect textual references to medical information such as medical condition, treatment, tests and results, and medications. This version uses a new model and changes the way some entities are returned in the output. For more information, see [DetectEntitiesV2](https://docs.aws.amazon.com/comprehend/latest/dg/API_medical_DetectEntitiesV2.html).\n",
    "\n",
    "- [Detect PHI (Verdion 1)](https://docs.aws.amazon.com/comprehend/latest/dg/how-medical-phi.html) —Examine unstructured clinical text to detect textual references to protected health information (PHI) such as names and addresses.\n",
    "\n",
    "\n",
    "In this workshop, we will be using the detect entities function ([detect_entities_v2](https://docs.aws.amazon.com/comprehend/latest/dg/extracted-med-info-V2.html)) to extract medical conditions. In the following cell, we will be processing the text on each page in batches of 20,000 UTF-8 characters. This is because Comprehend Medical has a maximum document size of 20,000 bytes (reference: https://docs.aws.amazon.com/comprehend/latest/dg/guidelines-and-limits-med.html). Once we've processed the text, we will then stich up the response into a into a single variable where we can either save to a csv or use for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLength=10000\n",
    "\n",
    "comprehendResponse = []\n",
    "comprehend_medical_client = boto3.client(service_name='comprehendmedical', region_name='us-east-1')\n",
    "\n",
    "for page in doc.pages:\n",
    "    pageText = page.text\n",
    "    \n",
    "    for i in range(0, len(pageText), maxLength):\n",
    "        response = comprehend_medical_client.detect_entities_v2(Text=pageText[0+i:maxLength+i])\n",
    "        comprehendResponse.append(response)\n",
    "    patient_string = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review comprehend results\n",
    "The output of detect entities v2 can detect the following entities:\n",
    "\n",
    "\n",
    "- `MEDICAL_CONDITION`: The signs, symptoms, and diagnosis of medical conditions.\n",
    "- `Score` - The level of confidence that Amazon Comprehend Medical has in the accuracy of the detection\n",
    "- `Trait` - Contextual information for the entity\n",
    "\n",
    "Other information extracted by Comprehend Medical:\n",
    "- `MEDICATION`: Medication and dosage information for the patient.\n",
    "- `PROTECTED_HEALTH_INFORMATION`: patient's personal information, e.g. name, age, gender\n",
    "- `TEST_TREATMENT_PROCEDURE`: the procedures that are used to determine a medical condition.\n",
    "- `TIME_EXPRESSION`: Entities related to time when they are associated with a detected entity.\n",
    "\n",
    "For this workshop, we will be using the MEDICAL_CONDITION entity to train our machine learning model. Let us take a look at some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use util function to extract all the medical conditions, confidence score, trait from json file \n",
    "df_cm=extractMC_v2(comprehendResponse[0])\n",
    "df_cm['ID']=1\n",
    "df_cm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clean up resources\n",
    "\n",
    "Finally, run the following cell to clean up the S3 resource we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(textractObjectName).delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
